import os
import uuid
from typing import List, Dict
from datetime import datetime

from langchain_core.tools import tool
from langchain_community.tools.tavily_search import TavilySearchResults
from sentence_transformers import SentenceTransformer
from qdrant_client.http import models
from qdrant_client.http.models import Distance, VectorParams
from firecrawl import FirecrawlApp
import yfinance as yf
import pandas as pd

# --- 1. Qdrant íŒ©í† ë¦¬ì—ì„œ 'ê³µìœ  í´ë¼ì´ì–¸íŠ¸' ì„í¬íŠ¸ ---
# (ì´ ì½”ë“œê°€ ì‘ë™í•˜ë ¤ë©´ core/vector_db.py íŒŒì¼ì´ ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤)
try:
    from core.vector_db import qdrant_client 
except ImportError:
    print("!!! ì—ëŸ¬: 'core/vector_db.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”. !!!")
    # ì„ì‹œ ë°©í¸ìœ¼ë¡œ :memory: ëª¨ë“œ ì‚¬ìš©
    from qdrant_client import QdrantClient
    qdrant_client = QdrantClient(":memory:")
    print("--- [Tools] ê²½ê³ : 'core.vector_db'ë¥¼ ì°¾ì§€ ëª»í•´ ì„ì‹œ :memory: ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤. ---")


# --- 2. ê°ì„±ë¶„ì„ê¸° ì„í¬íŠ¸ ---
try:
    from agents.sentiment_analyzer import sentiment_analyzer
    print("--- [Tools] ê°ì„±ë¶„ì„ê¸° ë¡œë“œ ì™„ë£Œ ---")
except ImportError:
    print("--- [Tools] ê²½ê³ : 'agents/sentiment_analyzer.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°ì„±ë¶„ì„ ë¹„í™œì„±í™” ---")
    sentiment_analyzer = None


# API í‚¤ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
FIRECRAWL_API_KEY = os.getenv("FIRECRAWL_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

firecrawl_client = None
if FIRECRAWL_API_KEY:
    firecrawl_client = FirecrawlApp(api_key=FIRECRAWL_API_KEY)
    print("--- [Tools] Firecrawl í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ ---")
else:
    print("--- [Tools] ê²½ê³ : FIRECRAWL_API_KEYê°€ .envì— ì—†ìŠµë‹ˆë‹¤. 'ingest_news_qdrant' íˆ´ì´ ì‹¤íŒ¨í•©ë‹ˆë‹¤. ---")

# --- 3. ì„ë² ë”© ëª¨ë¸ ë³€ê²½: multilingual-e5-large ---
print("\n--- [Tools] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘... ---")
# â­ ë³€ê²½: all-MiniLM-L6-v2 (384ì°¨ì›) â†’ multilingual-e5-large (1024ì°¨ì›)
embedding_model = SentenceTransformer('intfloat/multilingual-e5-large')
EMBEDDING_DIMENSION = 1024  # â­ 384 â†’ 1024
COLLECTION_NAME = "sector_news_v2"  # â­ ìƒˆ ì»¬ë ‰ì…˜ ì´ë¦„
print(f"--- [Tools] ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ: multilingual-e5-large ({EMBEDDING_DIMENSION}ì°¨ì›) ---")

# --- 4. ì¶œì²˜ ì‹ ë¢°ë„ ë§µ ---
SOURCE_TRUST_MAP = {
    "samsung.com": 0.95,      # ì¦ê¶Œì‚¬ ë¦¬ì„œì¹˜
    "miraeasset.com": 0.95,
    "hankyung.com": 0.85,     # ê²½ì œ ì „ë¬¸ì§€
    "mk.co.kr": 0.85,
    "naver.com": 0.70,        # í¬í„¸ ë‰´ìŠ¤
    "daum.net": 0.70,
}

def get_trust_score(url: str) -> float:
    """URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ í›„ ì‹ ë¢°ë„ ì ìˆ˜ ë°˜í™˜"""
    try:
        from urllib.parse import urlparse
        domain = urlparse(url).netloc
        domain = domain.replace('www.', '')
        return SOURCE_TRUST_MAP.get(domain, 0.6)  # ê¸°ë³¸ê°’ 0.6
    except:
        return 0.6

# --- 5. íˆ´ ì •ì˜ (ì´ 3ê°œ) ---
@tool
def get_sector_etf_momentum(sector_name: str) -> dict:
    """
    (Agent 2) yfinanceë¥¼ ì‚¬ìš©í•´ ì„¹í„° ETFì˜ ê¸°ë³¸ ëª¨ë©˜í…€(ì˜ˆ: 50ì¼ ì´í‰ì„ )ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    print(f"\n[Agent 2 Tool] '{sector_name}' ëª¨ë©˜í…€ ë¶„ì„ ì‹œì‘...")
    
    # (ì„ì‹œ) ì‹¤ì œë¡œëŠ” ì„¹í„°ëª… <-> ETF í‹°ì»¤ ë§¤í•‘ í•„ìš”
    SECTOR_ETF_MAP = { 
        "ë°˜ë„ì²´": "SOXX", 
        "ë°”ì´ì˜¤": "XBI", 
        "AI": "BOTZ",
        "ë°©ìœ„ì‚°ì—…": "PPA",
        "ë¸”ë¡ì²´ì¸": "BLOK"
    }
    ticker = SECTOR_ETF_MAP.get(sector_name, "SPY") # ê¸°ë³¸ê°’ SPY
    
    try:
        data = yf.download(ticker, period="3mo", progress=False)
        if data.empty:
            return {"error": f"No data found for {ticker}"}
            
        data['SMA_50'] = data['Close'].rolling(window=50).mean()
        latest_close = data['Close'].iloc[-1]
        latest_sma = data['SMA_50'].iloc[-1]
        momentum_signal = "Positive" if latest_close > latest_sma else "Negative"
        
        print(f"[Agent 2 Tool] '{sector_name}' ëª¨ë©˜í…€ ë¶„ì„ ì™„ë£Œ.")
        return {
            "ticker": ticker,
            "latest_close": round(latest_close, 2),
            "sma_50": round(latest_sma, 2),
            "momentum_signal": momentum_signal
        }
    except Exception as e:
        return {"error": str(e)}

@tool
def search_realtime_news_tavily(query: str) -> List[Dict]:
    """
    (Agent 5 - ë‹¨ê¸° ê¸°ì–µ) Tavilyë¥¼ ì‚¬ìš©í•´ 'ì§€ê¸ˆ ì´ ìˆœê°„'ì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ 
    ê²€ìƒ‰í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤. "ìµœì‹  ì†ë³´"ë‚˜ "ì˜¤ëŠ˜ ë™í–¥"ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print(f"\n[Agent 5 Tool - Tavily] ì‹¤ì‹œê°„ ê²€ìƒ‰ ì‹œì‘. ì¿¼ë¦¬: '{query}'")
    if not TAVILY_API_KEY:
        return [{"error": "TAVILY_API_KEYê°€ .envì— ì—†ìŠµë‹ˆë‹¤."}]
    
    try:
        tavily_tool = TavilySearchResults(max_results=3, tavily_api_key=TAVILY_API_KEY)
        results = tavily_tool.invoke(query)
        print(f"[Agent 5 Tool - Tavily] ì‹¤ì‹œê°„ ê²€ìƒ‰ ì™„ë£Œ. {len(results)}ê°œ ê²°ê³¼ ë°˜í™˜.")
        return results # (ì´ë¯¸ ìš”ì•½ëœ ë‚´ìš©ê³¼ ì¶œì²˜ URLì´ í¬í•¨ëœ dict ë¦¬ìŠ¤íŠ¸)
    except Exception as e:
        return [{"error": str(e)}]

# 4. ë‰´ìŠ¤ ìˆ˜ì§‘ ì €ì¥ ê²€ìƒ‰ 
@tool
def ingest_and_search_qdrant(sector_name: str) -> dict:
    """
    â­ ìˆ˜ì •ëœ í•¨ìˆ˜: FinBERT ê°ì„±ë¶„ì„ + ê°œì„ ëœ Qdrant ìŠ¤í‚¤ë§ˆ
    
    (Agent 5 - ì¥ê¸° ê¸°ì–µ) 
    1. Firecrawlë¡œ 'sector_name' í‚¤ì›Œë“œ ë‰´ìŠ¤ ìˆ˜ì§‘
    2. FinBERT-KRë¡œ ê°ì„±ë¶„ì„
    3. í’ë¶€í•œ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ Qdrant DBì— ì €ì¥
    4. Qdrant DBì—ì„œ 'sector_name'ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤ ê²€ìƒ‰
    """
    print(f"\n[Agent 5 Tool - Qdrant/Firecrawl] ì¥ê¸° ê¸°ì–µ RAG ì‹œì‘. ì„¹í„°: '{sector_name}'")
    
    # --- 1. ìˆ˜ì§‘(Ingest) ---
    if not firecrawl_client:
        return {"error": "Firecrawl í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (.env í‚¤ í™•ì¸)"}
    
    try:
        print(f"  > [Firecrawl] '{sector_name}' ì„¹í„° ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œë„...")
        # Firecrawlì˜ searchëŠ” SearchData ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        search_data = firecrawl_client.search(
            query=f"{sector_name} ì„¹í„° ë‰´ìŠ¤ í•œêµ­",
            scrape_options={
                "max_results": 10,
                "country": "kr",
                "time_range": "1y"
            }
        )
        
        # SearchData ê°ì²´ì—ì„œ web ê²°ê³¼ë¥¼ ì¶”ì¶œí•˜ì—¬ Qdrant í¬ì¸íŠ¸ë¡œ ë³€í™˜
        # ë‰´ìŠ¤ ë°ì´í„° ì¶”ì¶œ
        news_list = []
        web_results = search_data.web if hasattr(search_data, 'web') else []

        for item in web_results:
            description = item.description if hasattr(item, 'description') else ''
            if description and len(description) > 50:  # ë„ˆë¬´ ì§§ì€ ì„¤ëª…ì€ ì œì™¸
                news_list.append({
                    "text": description,
                    "title": item.title if hasattr(item, 'title') else '',
                    "url": item.url if hasattr(item, 'url') else ''
                })
        
        if not news_list:
             print("  > [Firecrawl] í¬ë¡¤ë§ëœ ë‰´ìŠ¤ê°€ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
             return {"error": "Firecrawlì—ì„œ ìœ íš¨í•œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}
        
        print(f"  > [Firecrawl] {len(news_list)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")

        # --- 2. ê°ì„±ë¶„ì„ (FinBERT í•˜ì´ë¸Œë¦¬ë“œ) ---
        if sentiment_analyzer:
            print(f" > [FinBERT] ê°ì„±ë¶„ì„ ì‹œì‘...")
            analyzed_news = sentiment_analyzer.analyze_batch(news_list)
        else:
            print("  > [ê²½ê³ ] ê°ì„±ë¶„ì„ê¸° ë¹„í™œì„±í™”. ê¸°ë³¸ê°’ ì‚¬ìš©")
            analyzed_news = news_list

        # --- 3. Qdrant ì €ì¥ (ê°œì„ ëœ ìŠ¤í‚¤ë§ˆ) ---
        print(f"  > [Qdrant] ë²¡í„° DB ì €ì¥ ì‹œì‘...")
        points_to_upsert = []
        
        for news in analyzed_news:
            # ì„ë² ë”© ìƒì„± (ì›ë³¸ í…ìŠ¤íŠ¸ ì „ì²´)
            vector = embedding_model.encode(news['text']).tolist()
            
            # â­ ê°œì„ ëœ Payload ìŠ¤í‚¤ë§ˆ
            payload = {
                # í•µì‹¬ í•„ë“œ
                "text": news['text'],           # ì›ë³¸ ì „ì²´
                "title": news.get('title', ''),
                "sector": sector_name,
                
                # ê°ì„±ë¶„ì„ (FinBERT)
                "sentiment": news.get('sentiment', 'neutral'),
                "sentiment_score": news.get('sentiment_score', 0.0),
                "sentiment_confidence": news.get('sentiment_confidence', 0.0),
                "analysis_method": news.get('method', 'none'),
                
                # ì¶œì²˜ ì‹ ë¢°ë„
                "source_url": news.get('url', ''),
                "source_domain": news.get('url', '').split('/')[2] if '/' in news.get('url', '') else '',
                "source_trust_score": get_trust_score(news.get('url', '')),
                
                # ì‹œê°„ ì •ë³´
                "published_at": datetime.now().isoformat(),
                "crawled_at": datetime.now().isoformat(),
                
                # ì¤‘ë³µ ë°©ì§€
                "content_hash": str(uuid.uuid4()),  # ì‹¤ì œë¡  MD5(title+date)
                
                # ì¶”ê°€ ë©”íƒ€
                "companies": [],  # TODO: NERë¡œ ê¸°ì—…ëª… ì¶”ì¶œ
                "tags": [],       # TODO: í‚¤ì›Œë“œ ì¶”ì¶œ
            }
            
            points_to_upsert.append(
                models.PointStruct(
                    id=str(uuid.uuid4()),
                    vector=vector,
                    payload=payload
                )
            )
        
        # Qdrant upsert
        qdrant_client.upsert(
            collection_name=COLLECTION_NAME,
            points=points_to_upsert
        )
        print(f"  > [Qdrant] {len(points_to_upsert)}ê°œ ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ")

    except Exception as e:
        print(f"  > !!! Firecrawl/Qdrant ìˆ˜ì§‘ ë‹¨ê³„ ì—ëŸ¬: {e}")
        return {"error": str(e)}

    # --- 4. ê²€ìƒ‰(Search) ---
    try:
        query_vector = embedding_model.encode(f"{sector_name} ì„¹í„°ì˜ ì „ë°˜ì ì¸ ë™í–¥ê³¼ íˆ¬ì ì „ë§").tolist()
        search_results = qdrant_client.search(
            collection_name=COLLECTION_NAME,
            query_vector=query_vector,
            limit=5,  # â­ 3 â†’ 5ë¡œ ì¦ê°€
            # â­ í•„í„° ì¶”ê°€ (ì„ íƒ)
            # query_filter=models.Filter(
            #     must=[
            #         models.FieldCondition(
            #             key="sentiment_confidence",
            #             range=models.Range(gte=0.5)
            #         )
            #     ]
            # )
        )
        
        results = [
            {
                "score": res.score,
                "payload": res.payload,
                # ì£¼ìš” ì •ë³´ë§Œ ì¶”ì¶œ (LLMì—ê²Œ ì „ë‹¬)
                "summary": {
                    "title": res.payload.get('title', ''),
                    "sentiment": res.payload.get('sentiment', 'neutral'),
                    "sentiment_score": res.payload.get('sentiment_score', 0.0),
                    "source": res.payload.get('source_domain', ''),
                    "text_preview": res.payload.get('text', '')[:200] + "..."
                }
            }
            for res in search_results
        ]
        
        print(f"  > [Qdrant] RAG ê²€ìƒ‰ ì™„ë£Œ. {len(results)}ê°œ ê²°ê³¼ ë°˜í™˜.")
        return {"query": sector_name, "results": results}
        
    except Exception as e:
        print(f"  > !!! Qdrant ê²€ìƒ‰ ë‹¨ê³„ ì—ëŸ¬: {e}")
        return {"error": str(e)}

# --- 6. íˆ´ ë¦¬ìŠ¤íŠ¸ ---
available_tools = [
    get_sector_etf_momentum,
    search_realtime_news_tavily,
    ingest_and_search_qdrant
]

# --- 7. Qdrant ì»¬ë ‰ì…˜ ì´ˆê¸°í™” (ìƒˆ ìŠ¤í‚¤ë§ˆ) ---
def _initialize_qdrant_collection():
    """
    â­ ìˆ˜ì •: multilingual-e5-large (1024ì°¨ì›) ì»¬ë ‰ì…˜ ìƒì„±
    ê¸°ì¡´ 'sector_news_rag' ì»¬ë ‰ì…˜ì€ ë¬´ì‹œí•˜ê³  'sector_news_v2'ë§Œ ê´€ë¦¬
    """
    print("\n--- [Tools] Qdrant ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì‹œë„... ---")
    try:
        # ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì—ëŸ¬ ë°œìƒ)
        try:
            qdrant_client.get_collection(collection_name=COLLECTION_NAME)
            print(f"âœ… '{COLLECTION_NAME}' ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. (1024ì°¨ì›)")
        except Exception:
            print(f"ğŸ“¦ '{COLLECTION_NAME}' ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤... (1024ì°¨ì›)")
            qdrant_client.recreate_collection(
                collection_name=COLLECTION_NAME,
                vectors_config=VectorParams(
                    size=EMBEDDING_DIMENSION,  # 1024
                    distance=Distance.COSINE
                )
            )
            
            # â­ Payload ì¸ë±ìŠ¤ ìƒì„± (í•„í„°ë§ ì„±ëŠ¥)
            print(f"  > Payload ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
            qdrant_client.create_payload_index(
                collection_name=COLLECTION_NAME,
                field_name="sector",
                field_schema=models.PayloadSchemaType.KEYWORD
            )
            qdrant_client.create_payload_index(
                collection_name=COLLECTION_NAME,
                field_name="sentiment",
                field_schema=models.PayloadSchemaType.KEYWORD
            )
            
            print(f"âœ… '{COLLECTION_NAME}' ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ ({EMBEDDING_DIMENSION}ì°¨ì›)")

    except Exception as e:
        print(f"--- [Tools] !!! Qdrant ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬: {e} ---")

# â­ ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì‹¤í–‰
_initialize_qdrant_collection()

# â­ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì •ë¦¬ ì•ˆë‚´ (ì„ íƒ)
try:
    old_collections = qdrant_client.get_collections().collections
    old_names = [c.name for c in old_collections if c.name != COLLECTION_NAME]
    if old_names:
        print(f"\nğŸ’¡ ì°¸ê³ : ê¸°ì¡´ ì»¬ë ‰ì…˜ ë°œê²¬ {old_names}")
        print(f"   ì‚­ì œí•˜ë ¤ë©´: python -c \"from core.vector_db import qdrant_client; qdrant_client.delete_collection('{old_names[0]}')\"")
except:
    pass